{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "396d2c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "D:\\anaconda\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "D:\\anaconda\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "D:\\anaconda\\lib\\site-packages\\dask\\dataframe\\__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import (roc_auc_score, accuracy_score, f1_score, confusion_matrix)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d146aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b126adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the global random seed\n",
    "def set_global_seed(seed_value):\n",
    "    random.seed(seed_value)  # Setting Python's random seed\n",
    "    np.random.seed(seed_value)  # Set NumPy random seed\n",
    "\n",
    "set_global_seed(66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb9eb2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = pd.read_csv('xxx.csv')\n",
    "x = data.drop(columns=['xxx']).values\n",
    "y = data['xxx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44799fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6dfc4d",
   "metadata": {},
   "source": [
    "# Data balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "109423fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from imblearn.over_sampling import BorderlineSMOTE, KMeansSMOTE, RandomOverSampler, SVMSMOTE, SMOTE\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eff79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Use BorderlineSMOTE\n",
    "borderline_smote = BorderlineSMOTE(random_state=0)\n",
    "train_x_borderline, train_y_borderline = borderline_smote.fit_resample(train_x, train_y)\n",
    "print('BorderlineSMOTE Resampled dataset shape %s' % Counter(train_y_borderline))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c2782e5",
   "metadata": {},
   "source": [
    "# 2. Use KMeansSMOTE\n",
    "kmeans_smote = KMeansSMOTE(random_state=0)\n",
    "train_x_kmeans, train_y_kmeans = kmeans_smote.fit_resample(train_x, train_y)\n",
    "print('KMeansSMOTE Resampled dataset shape %s' % Counter(train_y_kmeans))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1331aa3",
   "metadata": {},
   "source": [
    "# 3. Use RandomOverSampler\n",
    "random_oversampler = RandomOverSampler(random_state=0)\n",
    "train_x_random, train_y_random = random_oversampler.fit_resample(train_x, train_y)\n",
    "print('RandomOverSampler Resampled dataset shape %s' % Counter(train_y_random))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "689059d2",
   "metadata": {},
   "source": [
    "# 4. Use SVMSMOTE\n",
    "svm_smote = SVMSMOTE(random_state=0)\n",
    "train_x_svm, train_y_svm = svm_smote.fit_resample(train_x, train_y)\n",
    "print('SVMSMOTE Resampled dataset shape %s' % Counter(train_y_svm))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29b88f02",
   "metadata": {},
   "source": [
    "# 5. Use SMOTE\n",
    "smote = SMOTE(random_state=0)\n",
    "train_x_smote, train_y_smote = smote.fit_resample(train_x, train_y)\n",
    "print('SMOTE Resampled dataset shape %s' % Counter(train_y_smote))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26bc663f",
   "metadata": {},
   "source": [
    "# 6. Use SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "train_x_smote_tomek, train_y_smote_tomek = smote_tomek.fit_resample(train_x, train_y)\n",
    "print('SMOTETomek Resampled dataset shape %s' % Counter(train_y_smote_tomek))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2631933e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1035, 37), (259, 37), (1035,), (259,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,test_x.shape,train_y.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1825ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x_borderline\n",
    "train_y=train_y_borderline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f3af54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1262, 37), (259, 37), (1262,), (259,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape,test_x.shape,train_y.shape,test_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047f6df",
   "metadata": {},
   "source": [
    "# Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85b0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, roc_auc_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edd5e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameter search range\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']  # l1 regularisation requires the “liblinear” solver.\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': [5, 10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"Extra Trees\": {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'num_leaves': [31, 50, 100]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [100, 200, 500],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'max_depth': [6, 10, 15],\n",
    "        'colsample_bytree': [0.7, 0.8, 1.0]\n",
    "    },\n",
    "    \"CatBoost\": {\n",
    "        'iterations': [500, 1000],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'depth': [6, 10, 15]\n",
    "    },\n",
    "    \"Neural Network\": {\n",
    "        'hidden_layer_sizes': [(100,), (50, 50), (100, 50)],\n",
    "        'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "        'max_iter': [500, 1000]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define model dictionary (without optimisation parameters)\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"CatBoost\": CatBoostClassifier(silent=True),\n",
    "    \"Neural Network\": MLPClassifier(max_iter=1000)\n",
    "}\n",
    "\n",
    "# Optimal parameters and performance for storage\n",
    "best_models = {}\n",
    "results = {}\n",
    "\n",
    "# Perform hyperparameter optimisation on the model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Optimizing {model_name}...\")\n",
    "\n",
    "    # Using GridSearchCV for Hyperparameter Optimisation\n",
    "    search = GridSearchCV(\n",
    "        model, param_grids[model_name], \n",
    "        scoring='roc_auc',  # Using ROC AUC as an evaluation criterion\n",
    "        n_jobs=-1,  # Utilise all available CPU cores\n",
    "        cv=5,  # Five-fold cross-validation\n",
    "        verbose=1  # Output Process\n",
    "    )\n",
    "    \n",
    "    # Train and optimise the model\n",
    "    search.fit(train_x, train_y)\n",
    "    \n",
    "    # Storing optimal models and performance metrics\n",
    "    best_models[model_name] = search.best_estimator_\n",
    "    results[model_name] = {\n",
    "        \"Best Params\": search.best_params_,\n",
    "        \"Best Score (ROC AUC)\": search.best_score_\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12098b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to a CSV file\n",
    "results_df.to_csv('xxx.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295272d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate optimized models\n",
    "test_results = {}\n",
    "for model_name, model in best_models.items():\n",
    "    predictions = model.predict(test_x)\n",
    "    \n",
    "    # Get predicted probabilities for ROC AUC calculation\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        prob_predictions = model.predict_proba(test_x)[:, 1]  # Get the probability of the positive class\n",
    "    else:\n",
    "        prob_predictions = model.decision_function(test_x)\n",
    "    \n",
    "    # Calculate cross-validation metrics (using the same scoring method)\n",
    "    cv_accuracy = cross_val_score(model, train_x, train_y, cv=5, scoring='accuracy').mean()\n",
    "    cv_f1 = cross_val_score(model, train_x, train_y, cv=5, scoring='f1').mean()\n",
    "    cv_roc_auc = cross_val_score(model, train_x, train_y, cv=5, scoring='roc_auc').mean()\n",
    "    cv_precision = cross_val_score(model, train_x, train_y, cv=5, scoring='precision').mean()\n",
    "    cv_recall = cross_val_score(model, train_x, train_y, cv=5, scoring='recall').mean()\n",
    "\n",
    "    # Generate cross-validation predictions\n",
    "    cv_predictions = cross_val_predict(model, train_x, train_y, cv=5)\n",
    "\n",
    "    # Generate confusion matrix from cross-validation\n",
    "    cv_confusion_matrix = confusion_matrix(train_y, cv_predictions)\n",
    "    \n",
    "    # Calculate Precision and Recall on the test set\n",
    "    test_precision = precision_score(test_y, predictions)\n",
    "    test_recall = recall_score(test_y, predictions)\n",
    "    \n",
    "    test_results[model_name] = {\n",
    "        \"Accuracy\": accuracy_score(test_y, predictions),\n",
    "        \"F1 Score\": f1_score(test_y, predictions),\n",
    "        \"Precision\": test_precision,          # Precision on test set\n",
    "        \"Recall\": test_recall,                # Recall on test set\n",
    "        \"ROC AUC\": roc_auc_score(test_y, prob_predictions),\n",
    "        \"Confusion Matrix\": confusion_matrix(test_y, predictions),\n",
    "        \"CV Accuracy\": cv_accuracy,           # Accuracy from cross-validation\n",
    "        \"CV F1 Score\": cv_f1,                 # F1 Score from cross-validation\n",
    "        \"CV Precision\": cv_precision,         # Precision from cross-validation\n",
    "        \"CV Recall\": cv_recall,               # Recall from cross-validation\n",
    "        \"CV ROC AUC\": cv_roc_auc,             # ROC AUC from cross-validation\n",
    "        \"CV Confusion Matrix\": cv_confusion_matrix  # Confusion matrix from cross-validation\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7916c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix from cross-validation\n",
    "def plot_confusion_matrix(conf_matrix, model_name):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix for {model_name} (Cross-Validation)')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "# Assume test_results is the dictionary where you stored model results\n",
    "for model_name, results in test_results.items():\n",
    "    cv_conf_matrix = results[\"CV Confusion Matrix\"]\n",
    "    plot_confusion_matrix(cv_conf_matrix, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6f6afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to a CSV file\n",
    "test_results_df.to_csv('BorderlineSMOTE-结果.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
